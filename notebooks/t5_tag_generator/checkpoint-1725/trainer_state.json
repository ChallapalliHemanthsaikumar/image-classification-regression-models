{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 25.0,
  "eval_steps": 50,
  "global_step": 1725,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.14492753623188406,
      "grad_norm": 2.886505126953125,
      "learning_rate": 9.971014492753625e-05,
      "loss": 9.8627,
      "step": 10
    },
    {
      "epoch": 0.2898550724637681,
      "grad_norm": 3.576716899871826,
      "learning_rate": 9.91304347826087e-05,
      "loss": 9.1494,
      "step": 20
    },
    {
      "epoch": 0.43478260869565216,
      "grad_norm": 3.0544331073760986,
      "learning_rate": 9.860869565217392e-05,
      "loss": 9.0553,
      "step": 30
    },
    {
      "epoch": 0.5797101449275363,
      "grad_norm": 5.021748065948486,
      "learning_rate": 9.802898550724638e-05,
      "loss": 9.0442,
      "step": 40
    },
    {
      "epoch": 0.7246376811594203,
      "grad_norm": 4.948606014251709,
      "learning_rate": 9.75072463768116e-05,
      "loss": 8.4053,
      "step": 50
    },
    {
      "epoch": 0.7246376811594203,
      "eval_loss": 7.104399681091309,
      "eval_runtime": 0.2424,
      "eval_samples_per_second": 255.806,
      "eval_steps_per_second": 33.007,
      "step": 50
    },
    {
      "epoch": 0.8695652173913043,
      "grad_norm": 4.799410343170166,
      "learning_rate": 9.692753623188407e-05,
      "loss": 7.8977,
      "step": 60
    },
    {
      "epoch": 1.0144927536231885,
      "grad_norm": 4.090183734893799,
      "learning_rate": 9.634782608695652e-05,
      "loss": 6.986,
      "step": 70
    },
    {
      "epoch": 1.1594202898550725,
      "grad_norm": 6.217959403991699,
      "learning_rate": 9.576811594202899e-05,
      "loss": 6.0544,
      "step": 80
    },
    {
      "epoch": 1.3043478260869565,
      "grad_norm": 4.354971885681152,
      "learning_rate": 9.518840579710146e-05,
      "loss": 5.5538,
      "step": 90
    },
    {
      "epoch": 1.4492753623188406,
      "grad_norm": 10.764323234558105,
      "learning_rate": 9.460869565217391e-05,
      "loss": 4.4235,
      "step": 100
    },
    {
      "epoch": 1.4492753623188406,
      "eval_loss": 3.3347887992858887,
      "eval_runtime": 0.209,
      "eval_samples_per_second": 296.65,
      "eval_steps_per_second": 38.277,
      "step": 100
    },
    {
      "epoch": 1.5942028985507246,
      "grad_norm": 2.5327908992767334,
      "learning_rate": 9.402898550724638e-05,
      "loss": 3.9183,
      "step": 110
    },
    {
      "epoch": 1.7391304347826086,
      "grad_norm": 2.7750701904296875,
      "learning_rate": 9.344927536231885e-05,
      "loss": 3.1897,
      "step": 120
    },
    {
      "epoch": 1.8840579710144927,
      "grad_norm": 2.3028676509857178,
      "learning_rate": 9.28695652173913e-05,
      "loss": 3.165,
      "step": 130
    },
    {
      "epoch": 2.028985507246377,
      "grad_norm": 3.5392136573791504,
      "learning_rate": 9.228985507246377e-05,
      "loss": 3.0589,
      "step": 140
    },
    {
      "epoch": 2.1739130434782608,
      "grad_norm": 1.0936801433563232,
      "learning_rate": 9.171014492753624e-05,
      "loss": 2.811,
      "step": 150
    },
    {
      "epoch": 2.1739130434782608,
      "eval_loss": 2.331542730331421,
      "eval_runtime": 0.2094,
      "eval_samples_per_second": 296.114,
      "eval_steps_per_second": 38.208,
      "step": 150
    },
    {
      "epoch": 2.318840579710145,
      "grad_norm": 1.1032434701919556,
      "learning_rate": 9.11304347826087e-05,
      "loss": 2.7871,
      "step": 160
    },
    {
      "epoch": 2.463768115942029,
      "grad_norm": 1.0497769117355347,
      "learning_rate": 9.055072463768116e-05,
      "loss": 2.7071,
      "step": 170
    },
    {
      "epoch": 2.608695652173913,
      "grad_norm": 1.7943296432495117,
      "learning_rate": 8.997101449275362e-05,
      "loss": 2.4673,
      "step": 180
    },
    {
      "epoch": 2.753623188405797,
      "grad_norm": 1.2965847253799438,
      "learning_rate": 8.939130434782609e-05,
      "loss": 2.543,
      "step": 190
    },
    {
      "epoch": 2.898550724637681,
      "grad_norm": 1.8033491373062134,
      "learning_rate": 8.881159420289856e-05,
      "loss": 2.5092,
      "step": 200
    },
    {
      "epoch": 2.898550724637681,
      "eval_loss": 2.101823091506958,
      "eval_runtime": 0.222,
      "eval_samples_per_second": 279.28,
      "eval_steps_per_second": 36.036,
      "step": 200
    },
    {
      "epoch": 3.0434782608695654,
      "grad_norm": 6.25087833404541,
      "learning_rate": 8.823188405797101e-05,
      "loss": 2.2735,
      "step": 210
    },
    {
      "epoch": 3.1884057971014492,
      "grad_norm": 0.7863869667053223,
      "learning_rate": 8.765217391304348e-05,
      "loss": 2.281,
      "step": 220
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 1.8398723602294922,
      "learning_rate": 8.707246376811595e-05,
      "loss": 2.4014,
      "step": 230
    },
    {
      "epoch": 3.4782608695652173,
      "grad_norm": 0.8224440813064575,
      "learning_rate": 8.64927536231884e-05,
      "loss": 2.0986,
      "step": 240
    },
    {
      "epoch": 3.6231884057971016,
      "grad_norm": 1.6778651475906372,
      "learning_rate": 8.591304347826087e-05,
      "loss": 2.183,
      "step": 250
    },
    {
      "epoch": 3.6231884057971016,
      "eval_loss": 1.9913016557693481,
      "eval_runtime": 0.2092,
      "eval_samples_per_second": 296.354,
      "eval_steps_per_second": 38.239,
      "step": 250
    },
    {
      "epoch": 3.7681159420289854,
      "grad_norm": 0.8361384272575378,
      "learning_rate": 8.533333333333334e-05,
      "loss": 2.1743,
      "step": 260
    },
    {
      "epoch": 3.9130434782608696,
      "grad_norm": 0.7776171565055847,
      "learning_rate": 8.475362318840581e-05,
      "loss": 2.0216,
      "step": 270
    },
    {
      "epoch": 4.057971014492754,
      "grad_norm": 0.7164075970649719,
      "learning_rate": 8.417391304347828e-05,
      "loss": 2.0375,
      "step": 280
    },
    {
      "epoch": 4.202898550724638,
      "grad_norm": 0.7374756932258606,
      "learning_rate": 8.359420289855073e-05,
      "loss": 2.0297,
      "step": 290
    },
    {
      "epoch": 4.3478260869565215,
      "grad_norm": 0.6965571641921997,
      "learning_rate": 8.30144927536232e-05,
      "loss": 1.9359,
      "step": 300
    },
    {
      "epoch": 4.3478260869565215,
      "eval_loss": 1.9011420011520386,
      "eval_runtime": 0.2293,
      "eval_samples_per_second": 270.367,
      "eval_steps_per_second": 34.886,
      "step": 300
    },
    {
      "epoch": 4.492753623188406,
      "grad_norm": 0.7759113907814026,
      "learning_rate": 8.243478260869565e-05,
      "loss": 1.9402,
      "step": 310
    },
    {
      "epoch": 4.63768115942029,
      "grad_norm": 0.6682646870613098,
      "learning_rate": 8.185507246376812e-05,
      "loss": 1.9278,
      "step": 320
    },
    {
      "epoch": 4.782608695652174,
      "grad_norm": 1.170867681503296,
      "learning_rate": 8.127536231884059e-05,
      "loss": 1.9046,
      "step": 330
    },
    {
      "epoch": 4.927536231884058,
      "grad_norm": 0.8733558654785156,
      "learning_rate": 8.069565217391304e-05,
      "loss": 1.771,
      "step": 340
    },
    {
      "epoch": 5.072463768115942,
      "grad_norm": 0.7320165634155273,
      "learning_rate": 8.011594202898551e-05,
      "loss": 1.7395,
      "step": 350
    },
    {
      "epoch": 5.072463768115942,
      "eval_loss": 1.805872917175293,
      "eval_runtime": 0.2025,
      "eval_samples_per_second": 306.171,
      "eval_steps_per_second": 39.506,
      "step": 350
    },
    {
      "epoch": 5.217391304347826,
      "grad_norm": 0.8188929557800293,
      "learning_rate": 7.953623188405798e-05,
      "loss": 1.82,
      "step": 360
    },
    {
      "epoch": 5.36231884057971,
      "grad_norm": 0.7623034715652466,
      "learning_rate": 7.895652173913044e-05,
      "loss": 1.7881,
      "step": 370
    },
    {
      "epoch": 5.507246376811594,
      "grad_norm": 0.686290442943573,
      "learning_rate": 7.83768115942029e-05,
      "loss": 1.8064,
      "step": 380
    },
    {
      "epoch": 5.6521739130434785,
      "grad_norm": 0.7807340621948242,
      "learning_rate": 7.779710144927537e-05,
      "loss": 1.7672,
      "step": 390
    },
    {
      "epoch": 5.797101449275362,
      "grad_norm": 0.7787164449691772,
      "learning_rate": 7.721739130434783e-05,
      "loss": 1.6589,
      "step": 400
    },
    {
      "epoch": 5.797101449275362,
      "eval_loss": 1.7128872871398926,
      "eval_runtime": 0.2672,
      "eval_samples_per_second": 232.066,
      "eval_steps_per_second": 29.944,
      "step": 400
    },
    {
      "epoch": 5.942028985507246,
      "grad_norm": 2.8760666847229004,
      "learning_rate": 7.66376811594203e-05,
      "loss": 1.6202,
      "step": 410
    },
    {
      "epoch": 6.086956521739131,
      "grad_norm": 0.6666298508644104,
      "learning_rate": 7.605797101449275e-05,
      "loss": 1.6509,
      "step": 420
    },
    {
      "epoch": 6.231884057971015,
      "grad_norm": 0.7216749787330627,
      "learning_rate": 7.547826086956522e-05,
      "loss": 1.685,
      "step": 430
    },
    {
      "epoch": 6.3768115942028984,
      "grad_norm": 0.7329305410385132,
      "learning_rate": 7.489855072463769e-05,
      "loss": 1.6811,
      "step": 440
    },
    {
      "epoch": 6.521739130434782,
      "grad_norm": 0.7752726674079895,
      "learning_rate": 7.431884057971014e-05,
      "loss": 1.5889,
      "step": 450
    },
    {
      "epoch": 6.521739130434782,
      "eval_loss": 1.6390955448150635,
      "eval_runtime": 0.243,
      "eval_samples_per_second": 255.182,
      "eval_steps_per_second": 32.927,
      "step": 450
    },
    {
      "epoch": 6.666666666666667,
      "grad_norm": 0.7319177389144897,
      "learning_rate": 7.373913043478261e-05,
      "loss": 1.6301,
      "step": 460
    },
    {
      "epoch": 6.811594202898551,
      "grad_norm": 5.863491535186768,
      "learning_rate": 7.315942028985508e-05,
      "loss": 1.7166,
      "step": 470
    },
    {
      "epoch": 6.956521739130435,
      "grad_norm": 0.700554370880127,
      "learning_rate": 7.257971014492753e-05,
      "loss": 1.6012,
      "step": 480
    },
    {
      "epoch": 7.101449275362318,
      "grad_norm": 0.6704341173171997,
      "learning_rate": 7.2e-05,
      "loss": 1.6062,
      "step": 490
    },
    {
      "epoch": 7.246376811594203,
      "grad_norm": 0.7852058410644531,
      "learning_rate": 7.142028985507247e-05,
      "loss": 1.6523,
      "step": 500
    },
    {
      "epoch": 7.246376811594203,
      "eval_loss": 1.5818408727645874,
      "eval_runtime": 0.2946,
      "eval_samples_per_second": 210.423,
      "eval_steps_per_second": 27.151,
      "step": 500
    },
    {
      "epoch": 7.391304347826087,
      "grad_norm": 0.7675367593765259,
      "learning_rate": 7.084057971014492e-05,
      "loss": 1.4468,
      "step": 510
    },
    {
      "epoch": 7.536231884057971,
      "grad_norm": 1.2318490743637085,
      "learning_rate": 7.02608695652174e-05,
      "loss": 1.4305,
      "step": 520
    },
    {
      "epoch": 7.681159420289855,
      "grad_norm": 3.9978227615356445,
      "learning_rate": 6.968115942028985e-05,
      "loss": 1.571,
      "step": 530
    },
    {
      "epoch": 7.826086956521739,
      "grad_norm": 0.7892703413963318,
      "learning_rate": 6.910144927536232e-05,
      "loss": 1.6397,
      "step": 540
    },
    {
      "epoch": 7.971014492753623,
      "grad_norm": 0.6991059184074402,
      "learning_rate": 6.852173913043478e-05,
      "loss": 1.523,
      "step": 550
    },
    {
      "epoch": 7.971014492753623,
      "eval_loss": 1.5381547212600708,
      "eval_runtime": 0.2167,
      "eval_samples_per_second": 286.092,
      "eval_steps_per_second": 36.915,
      "step": 550
    },
    {
      "epoch": 8.115942028985508,
      "grad_norm": 0.6763067245483398,
      "learning_rate": 6.794202898550724e-05,
      "loss": 1.4118,
      "step": 560
    },
    {
      "epoch": 8.26086956521739,
      "grad_norm": 0.9057580828666687,
      "learning_rate": 6.736231884057971e-05,
      "loss": 1.5443,
      "step": 570
    },
    {
      "epoch": 8.405797101449275,
      "grad_norm": 0.660480260848999,
      "learning_rate": 6.678260869565218e-05,
      "loss": 1.416,
      "step": 580
    },
    {
      "epoch": 8.55072463768116,
      "grad_norm": 0.7322161793708801,
      "learning_rate": 6.620289855072464e-05,
      "loss": 1.5524,
      "step": 590
    },
    {
      "epoch": 8.695652173913043,
      "grad_norm": 138.54180908203125,
      "learning_rate": 6.562318840579711e-05,
      "loss": 1.4729,
      "step": 600
    },
    {
      "epoch": 8.695652173913043,
      "eval_loss": 1.4957417249679565,
      "eval_runtime": 0.2151,
      "eval_samples_per_second": 288.175,
      "eval_steps_per_second": 37.184,
      "step": 600
    },
    {
      "epoch": 8.840579710144928,
      "grad_norm": 1.0653133392333984,
      "learning_rate": 6.504347826086957e-05,
      "loss": 1.6377,
      "step": 610
    },
    {
      "epoch": 8.985507246376812,
      "grad_norm": 0.788464367389679,
      "learning_rate": 6.446376811594204e-05,
      "loss": 1.5061,
      "step": 620
    },
    {
      "epoch": 9.130434782608695,
      "grad_norm": 0.8491808176040649,
      "learning_rate": 6.38840579710145e-05,
      "loss": 1.4399,
      "step": 630
    },
    {
      "epoch": 9.27536231884058,
      "grad_norm": 0.8339669108390808,
      "learning_rate": 6.330434782608696e-05,
      "loss": 1.4978,
      "step": 640
    },
    {
      "epoch": 9.420289855072463,
      "grad_norm": 105.72901916503906,
      "learning_rate": 6.272463768115943e-05,
      "loss": 1.5877,
      "step": 650
    },
    {
      "epoch": 9.420289855072463,
      "eval_loss": 1.4586113691329956,
      "eval_runtime": 0.2222,
      "eval_samples_per_second": 279.006,
      "eval_steps_per_second": 36.001,
      "step": 650
    },
    {
      "epoch": 9.565217391304348,
      "grad_norm": 0.9965765476226807,
      "learning_rate": 6.21449275362319e-05,
      "loss": 1.4442,
      "step": 660
    },
    {
      "epoch": 9.710144927536232,
      "grad_norm": 1.4623751640319824,
      "learning_rate": 6.156521739130435e-05,
      "loss": 1.3128,
      "step": 670
    },
    {
      "epoch": 9.855072463768115,
      "grad_norm": 1.027180790901184,
      "learning_rate": 6.098550724637682e-05,
      "loss": 1.3978,
      "step": 680
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.8238418698310852,
      "learning_rate": 6.040579710144928e-05,
      "loss": 1.4617,
      "step": 690
    },
    {
      "epoch": 10.144927536231885,
      "grad_norm": 0.7092347741127014,
      "learning_rate": 5.982608695652174e-05,
      "loss": 1.4271,
      "step": 700
    },
    {
      "epoch": 10.144927536231885,
      "eval_loss": 1.4307353496551514,
      "eval_runtime": 0.2229,
      "eval_samples_per_second": 278.13,
      "eval_steps_per_second": 35.888,
      "step": 700
    },
    {
      "epoch": 10.289855072463768,
      "grad_norm": 2.114908456802368,
      "learning_rate": 5.9246376811594204e-05,
      "loss": 1.3795,
      "step": 710
    },
    {
      "epoch": 10.434782608695652,
      "grad_norm": 0.676960825920105,
      "learning_rate": 5.866666666666667e-05,
      "loss": 1.4964,
      "step": 720
    },
    {
      "epoch": 10.579710144927537,
      "grad_norm": 0.8048569560050964,
      "learning_rate": 5.8086956521739133e-05,
      "loss": 1.5118,
      "step": 730
    },
    {
      "epoch": 10.72463768115942,
      "grad_norm": 2.942639112472534,
      "learning_rate": 5.7507246376811595e-05,
      "loss": 1.3937,
      "step": 740
    },
    {
      "epoch": 10.869565217391305,
      "grad_norm": 0.5508992075920105,
      "learning_rate": 5.6927536231884057e-05,
      "loss": 1.3017,
      "step": 750
    },
    {
      "epoch": 10.869565217391305,
      "eval_loss": 1.4113842248916626,
      "eval_runtime": 0.2067,
      "eval_samples_per_second": 300.004,
      "eval_steps_per_second": 38.71,
      "step": 750
    },
    {
      "epoch": 11.014492753623188,
      "grad_norm": 2.2857532501220703,
      "learning_rate": 5.6347826086956525e-05,
      "loss": 1.3367,
      "step": 760
    },
    {
      "epoch": 11.159420289855072,
      "grad_norm": 0.6199012994766235,
      "learning_rate": 5.5768115942028986e-05,
      "loss": 1.4847,
      "step": 770
    },
    {
      "epoch": 11.304347826086957,
      "grad_norm": 0.6457696557044983,
      "learning_rate": 5.518840579710145e-05,
      "loss": 1.4008,
      "step": 780
    },
    {
      "epoch": 11.44927536231884,
      "grad_norm": 1.6748454570770264,
      "learning_rate": 5.4608695652173916e-05,
      "loss": 1.3544,
      "step": 790
    },
    {
      "epoch": 11.594202898550725,
      "grad_norm": 0.7637040019035339,
      "learning_rate": 5.402898550724638e-05,
      "loss": 1.3828,
      "step": 800
    },
    {
      "epoch": 11.594202898550725,
      "eval_loss": 1.3985942602157593,
      "eval_runtime": 0.2008,
      "eval_samples_per_second": 308.813,
      "eval_steps_per_second": 39.847,
      "step": 800
    },
    {
      "epoch": 11.73913043478261,
      "grad_norm": 0.9639186859130859,
      "learning_rate": 5.344927536231884e-05,
      "loss": 1.3566,
      "step": 810
    },
    {
      "epoch": 11.884057971014492,
      "grad_norm": 0.7314063310623169,
      "learning_rate": 5.28695652173913e-05,
      "loss": 1.3564,
      "step": 820
    },
    {
      "epoch": 12.028985507246377,
      "grad_norm": 0.7501114010810852,
      "learning_rate": 5.228985507246377e-05,
      "loss": 1.3457,
      "step": 830
    },
    {
      "epoch": 12.173913043478262,
      "grad_norm": 3.9294016361236572,
      "learning_rate": 5.171014492753623e-05,
      "loss": 1.5024,
      "step": 840
    },
    {
      "epoch": 12.318840579710145,
      "grad_norm": 2.229616165161133,
      "learning_rate": 5.113043478260869e-05,
      "loss": 1.3242,
      "step": 850
    },
    {
      "epoch": 12.318840579710145,
      "eval_loss": 1.384049892425537,
      "eval_runtime": 0.2083,
      "eval_samples_per_second": 297.593,
      "eval_steps_per_second": 38.399,
      "step": 850
    },
    {
      "epoch": 12.46376811594203,
      "grad_norm": 0.6923454999923706,
      "learning_rate": 5.0550724637681154e-05,
      "loss": 1.3985,
      "step": 860
    },
    {
      "epoch": 12.608695652173914,
      "grad_norm": 0.9806120991706848,
      "learning_rate": 4.997101449275363e-05,
      "loss": 1.2906,
      "step": 870
    },
    {
      "epoch": 12.753623188405797,
      "grad_norm": 0.6354376077651978,
      "learning_rate": 4.939130434782609e-05,
      "loss": 1.3462,
      "step": 880
    },
    {
      "epoch": 12.898550724637682,
      "grad_norm": 4.69228982925415,
      "learning_rate": 4.881159420289855e-05,
      "loss": 1.2275,
      "step": 890
    },
    {
      "epoch": 13.043478260869565,
      "grad_norm": 0.8628876805305481,
      "learning_rate": 4.8231884057971014e-05,
      "loss": 1.3753,
      "step": 900
    },
    {
      "epoch": 13.043478260869565,
      "eval_loss": 1.3693677186965942,
      "eval_runtime": 0.2336,
      "eval_samples_per_second": 265.45,
      "eval_steps_per_second": 34.252,
      "step": 900
    },
    {
      "epoch": 13.18840579710145,
      "grad_norm": 0.9823859333992004,
      "learning_rate": 4.765217391304348e-05,
      "loss": 1.3813,
      "step": 910
    },
    {
      "epoch": 13.333333333333334,
      "grad_norm": 1.056862235069275,
      "learning_rate": 4.7072463768115944e-05,
      "loss": 1.3195,
      "step": 920
    },
    {
      "epoch": 13.478260869565217,
      "grad_norm": 0.7406336665153503,
      "learning_rate": 4.6492753623188405e-05,
      "loss": 1.3884,
      "step": 930
    },
    {
      "epoch": 13.623188405797102,
      "grad_norm": 1.8191906213760376,
      "learning_rate": 4.591304347826087e-05,
      "loss": 1.2551,
      "step": 940
    },
    {
      "epoch": 13.768115942028986,
      "grad_norm": 1.4624501466751099,
      "learning_rate": 4.5333333333333335e-05,
      "loss": 1.3042,
      "step": 950
    },
    {
      "epoch": 13.768115942028986,
      "eval_loss": 1.3574734926223755,
      "eval_runtime": 0.2814,
      "eval_samples_per_second": 220.343,
      "eval_steps_per_second": 28.431,
      "step": 950
    },
    {
      "epoch": 13.91304347826087,
      "grad_norm": 0.7524444460868835,
      "learning_rate": 4.47536231884058e-05,
      "loss": 1.3722,
      "step": 960
    },
    {
      "epoch": 14.057971014492754,
      "grad_norm": 0.6526268720626831,
      "learning_rate": 4.4173913043478265e-05,
      "loss": 1.2918,
      "step": 970
    },
    {
      "epoch": 14.202898550724637,
      "grad_norm": 0.940779447555542,
      "learning_rate": 4.359420289855073e-05,
      "loss": 1.2814,
      "step": 980
    },
    {
      "epoch": 14.347826086956522,
      "grad_norm": 0.8289520740509033,
      "learning_rate": 4.3014492753623195e-05,
      "loss": 1.289,
      "step": 990
    },
    {
      "epoch": 14.492753623188406,
      "grad_norm": 1.800647497177124,
      "learning_rate": 4.2434782608695657e-05,
      "loss": 1.4255,
      "step": 1000
    },
    {
      "epoch": 14.492753623188406,
      "eval_loss": 1.3465718030929565,
      "eval_runtime": 0.3486,
      "eval_samples_per_second": 177.852,
      "eval_steps_per_second": 22.949,
      "step": 1000
    },
    {
      "epoch": 14.63768115942029,
      "grad_norm": 0.7987436056137085,
      "learning_rate": 4.185507246376812e-05,
      "loss": 1.3151,
      "step": 1010
    },
    {
      "epoch": 14.782608695652174,
      "grad_norm": 1.082332730293274,
      "learning_rate": 4.127536231884058e-05,
      "loss": 1.2848,
      "step": 1020
    },
    {
      "epoch": 14.927536231884059,
      "grad_norm": 0.8703082203865051,
      "learning_rate": 4.069565217391305e-05,
      "loss": 1.296,
      "step": 1030
    },
    {
      "epoch": 15.072463768115941,
      "grad_norm": 0.7791621685028076,
      "learning_rate": 4.011594202898551e-05,
      "loss": 1.3271,
      "step": 1040
    },
    {
      "epoch": 15.217391304347826,
      "grad_norm": 3.4686625003814697,
      "learning_rate": 3.953623188405797e-05,
      "loss": 1.2558,
      "step": 1050
    },
    {
      "epoch": 15.217391304347826,
      "eval_loss": 1.3362535238265991,
      "eval_runtime": 0.2571,
      "eval_samples_per_second": 241.105,
      "eval_steps_per_second": 31.11,
      "step": 1050
    },
    {
      "epoch": 15.36231884057971,
      "grad_norm": 1.774119257926941,
      "learning_rate": 3.895652173913043e-05,
      "loss": 1.3257,
      "step": 1060
    },
    {
      "epoch": 15.507246376811594,
      "grad_norm": 0.6937595009803772,
      "learning_rate": 3.83768115942029e-05,
      "loss": 1.3532,
      "step": 1070
    },
    {
      "epoch": 15.652173913043478,
      "grad_norm": 0.8535218238830566,
      "learning_rate": 3.779710144927536e-05,
      "loss": 1.2224,
      "step": 1080
    },
    {
      "epoch": 15.797101449275363,
      "grad_norm": 0.6664550304412842,
      "learning_rate": 3.7217391304347824e-05,
      "loss": 1.1771,
      "step": 1090
    },
    {
      "epoch": 15.942028985507246,
      "grad_norm": 1.2380988597869873,
      "learning_rate": 3.663768115942029e-05,
      "loss": 1.4615,
      "step": 1100
    },
    {
      "epoch": 15.942028985507246,
      "eval_loss": 1.3267799615859985,
      "eval_runtime": 0.3954,
      "eval_samples_per_second": 156.79,
      "eval_steps_per_second": 20.231,
      "step": 1100
    },
    {
      "epoch": 16.08695652173913,
      "grad_norm": 0.6794705390930176,
      "learning_rate": 3.6057971014492754e-05,
      "loss": 1.2723,
      "step": 1110
    },
    {
      "epoch": 16.231884057971016,
      "grad_norm": 0.5567586421966553,
      "learning_rate": 3.5478260869565216e-05,
      "loss": 1.2418,
      "step": 1120
    },
    {
      "epoch": 16.3768115942029,
      "grad_norm": 0.6322453618049622,
      "learning_rate": 3.4898550724637684e-05,
      "loss": 1.23,
      "step": 1130
    },
    {
      "epoch": 16.52173913043478,
      "grad_norm": 3.786559581756592,
      "learning_rate": 3.4318840579710146e-05,
      "loss": 1.2561,
      "step": 1140
    },
    {
      "epoch": 16.666666666666668,
      "grad_norm": 0.6312272548675537,
      "learning_rate": 3.3739130434782614e-05,
      "loss": 1.3029,
      "step": 1150
    },
    {
      "epoch": 16.666666666666668,
      "eval_loss": 1.3233224153518677,
      "eval_runtime": 0.3814,
      "eval_samples_per_second": 162.578,
      "eval_steps_per_second": 20.978,
      "step": 1150
    },
    {
      "epoch": 16.81159420289855,
      "grad_norm": 0.8387395143508911,
      "learning_rate": 3.3159420289855075e-05,
      "loss": 1.3827,
      "step": 1160
    },
    {
      "epoch": 16.956521739130434,
      "grad_norm": 3.014188528060913,
      "learning_rate": 3.257971014492754e-05,
      "loss": 1.2694,
      "step": 1170
    },
    {
      "epoch": 17.10144927536232,
      "grad_norm": 0.8672052621841431,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 1.2641,
      "step": 1180
    },
    {
      "epoch": 17.246376811594203,
      "grad_norm": 0.5727359652519226,
      "learning_rate": 3.142028985507247e-05,
      "loss": 1.2146,
      "step": 1190
    },
    {
      "epoch": 17.391304347826086,
      "grad_norm": 0.9899303913116455,
      "learning_rate": 3.084057971014493e-05,
      "loss": 1.2317,
      "step": 1200
    },
    {
      "epoch": 17.391304347826086,
      "eval_loss": 1.316327452659607,
      "eval_runtime": 0.355,
      "eval_samples_per_second": 174.634,
      "eval_steps_per_second": 22.533,
      "step": 1200
    },
    {
      "epoch": 17.536231884057973,
      "grad_norm": 0.7935760021209717,
      "learning_rate": 3.0260869565217393e-05,
      "loss": 1.3308,
      "step": 1210
    },
    {
      "epoch": 17.681159420289855,
      "grad_norm": 1.1971244812011719,
      "learning_rate": 2.9681159420289855e-05,
      "loss": 1.2885,
      "step": 1220
    },
    {
      "epoch": 17.82608695652174,
      "grad_norm": 1.022894263267517,
      "learning_rate": 2.910144927536232e-05,
      "loss": 1.3842,
      "step": 1230
    },
    {
      "epoch": 17.971014492753625,
      "grad_norm": 0.7197838425636292,
      "learning_rate": 2.852173913043478e-05,
      "loss": 1.3141,
      "step": 1240
    },
    {
      "epoch": 18.115942028985508,
      "grad_norm": 2.401832342147827,
      "learning_rate": 2.7942028985507246e-05,
      "loss": 1.3996,
      "step": 1250
    },
    {
      "epoch": 18.115942028985508,
      "eval_loss": 1.311855673789978,
      "eval_runtime": 0.2558,
      "eval_samples_per_second": 242.334,
      "eval_steps_per_second": 31.269,
      "step": 1250
    },
    {
      "epoch": 18.26086956521739,
      "grad_norm": 0.863714337348938,
      "learning_rate": 2.7362318840579708e-05,
      "loss": 1.2582,
      "step": 1260
    },
    {
      "epoch": 18.405797101449274,
      "grad_norm": 0.7142885327339172,
      "learning_rate": 2.6782608695652173e-05,
      "loss": 1.2754,
      "step": 1270
    },
    {
      "epoch": 18.55072463768116,
      "grad_norm": 0.7727733254432678,
      "learning_rate": 2.620289855072464e-05,
      "loss": 1.2452,
      "step": 1280
    },
    {
      "epoch": 18.695652173913043,
      "grad_norm": 0.6318703889846802,
      "learning_rate": 2.5623188405797106e-05,
      "loss": 1.3155,
      "step": 1290
    },
    {
      "epoch": 18.840579710144926,
      "grad_norm": 0.867729663848877,
      "learning_rate": 2.5043478260869568e-05,
      "loss": 1.2462,
      "step": 1300
    },
    {
      "epoch": 18.840579710144926,
      "eval_loss": 1.306408405303955,
      "eval_runtime": 0.2657,
      "eval_samples_per_second": 233.353,
      "eval_steps_per_second": 30.11,
      "step": 1300
    },
    {
      "epoch": 18.985507246376812,
      "grad_norm": 0.7986280918121338,
      "learning_rate": 2.446376811594203e-05,
      "loss": 1.2516,
      "step": 1310
    },
    {
      "epoch": 19.130434782608695,
      "grad_norm": 1.6454862356185913,
      "learning_rate": 2.3884057971014494e-05,
      "loss": 1.2786,
      "step": 1320
    },
    {
      "epoch": 19.27536231884058,
      "grad_norm": 1.7357251644134521,
      "learning_rate": 2.330434782608696e-05,
      "loss": 1.3536,
      "step": 1330
    },
    {
      "epoch": 19.420289855072465,
      "grad_norm": 0.7783599495887756,
      "learning_rate": 2.272463768115942e-05,
      "loss": 1.2212,
      "step": 1340
    },
    {
      "epoch": 19.565217391304348,
      "grad_norm": 0.843005359172821,
      "learning_rate": 2.2144927536231886e-05,
      "loss": 1.1467,
      "step": 1350
    },
    {
      "epoch": 19.565217391304348,
      "eval_loss": 1.3036447763442993,
      "eval_runtime": 0.2287,
      "eval_samples_per_second": 271.106,
      "eval_steps_per_second": 34.981,
      "step": 1350
    },
    {
      "epoch": 19.71014492753623,
      "grad_norm": 1.927799105644226,
      "learning_rate": 2.1565217391304347e-05,
      "loss": 1.3152,
      "step": 1360
    },
    {
      "epoch": 19.855072463768117,
      "grad_norm": 1.0098059177398682,
      "learning_rate": 2.0985507246376812e-05,
      "loss": 1.2959,
      "step": 1370
    },
    {
      "epoch": 20.0,
      "grad_norm": 1.7981810569763184,
      "learning_rate": 2.0405797101449274e-05,
      "loss": 1.2899,
      "step": 1380
    },
    {
      "epoch": 20.144927536231883,
      "grad_norm": 0.6656966209411621,
      "learning_rate": 1.982608695652174e-05,
      "loss": 1.2396,
      "step": 1390
    },
    {
      "epoch": 20.28985507246377,
      "grad_norm": 0.8799342513084412,
      "learning_rate": 1.9246376811594204e-05,
      "loss": 1.3465,
      "step": 1400
    },
    {
      "epoch": 20.28985507246377,
      "eval_loss": 1.3008869886398315,
      "eval_runtime": 0.2166,
      "eval_samples_per_second": 286.223,
      "eval_steps_per_second": 36.932,
      "step": 1400
    },
    {
      "epoch": 20.434782608695652,
      "grad_norm": 0.7431547045707703,
      "learning_rate": 1.866666666666667e-05,
      "loss": 1.2462,
      "step": 1410
    },
    {
      "epoch": 20.579710144927535,
      "grad_norm": 0.6690337657928467,
      "learning_rate": 1.808695652173913e-05,
      "loss": 1.241,
      "step": 1420
    },
    {
      "epoch": 20.72463768115942,
      "grad_norm": 0.7441294193267822,
      "learning_rate": 1.7507246376811595e-05,
      "loss": 1.217,
      "step": 1430
    },
    {
      "epoch": 20.869565217391305,
      "grad_norm": 0.8871184587478638,
      "learning_rate": 1.692753623188406e-05,
      "loss": 1.2087,
      "step": 1440
    },
    {
      "epoch": 21.014492753623188,
      "grad_norm": 0.6235285401344299,
      "learning_rate": 1.634782608695652e-05,
      "loss": 1.271,
      "step": 1450
    },
    {
      "epoch": 21.014492753623188,
      "eval_loss": 1.2964129447937012,
      "eval_runtime": 0.2791,
      "eval_samples_per_second": 222.167,
      "eval_steps_per_second": 28.667,
      "step": 1450
    },
    {
      "epoch": 21.159420289855074,
      "grad_norm": 0.9513852000236511,
      "learning_rate": 1.5768115942028987e-05,
      "loss": 1.1861,
      "step": 1460
    },
    {
      "epoch": 21.304347826086957,
      "grad_norm": 0.6903122067451477,
      "learning_rate": 1.5188405797101448e-05,
      "loss": 1.247,
      "step": 1470
    },
    {
      "epoch": 21.44927536231884,
      "grad_norm": 3.3684470653533936,
      "learning_rate": 1.4608695652173915e-05,
      "loss": 1.3086,
      "step": 1480
    },
    {
      "epoch": 21.594202898550726,
      "grad_norm": 0.8971337080001831,
      "learning_rate": 1.4028985507246378e-05,
      "loss": 1.3018,
      "step": 1490
    },
    {
      "epoch": 21.73913043478261,
      "grad_norm": 0.9823610186576843,
      "learning_rate": 1.3449275362318841e-05,
      "loss": 1.2604,
      "step": 1500
    },
    {
      "epoch": 21.73913043478261,
      "eval_loss": 1.2946019172668457,
      "eval_runtime": 0.2215,
      "eval_samples_per_second": 279.855,
      "eval_steps_per_second": 36.11,
      "step": 1500
    },
    {
      "epoch": 21.884057971014492,
      "grad_norm": 15.262758255004883,
      "learning_rate": 1.2869565217391305e-05,
      "loss": 1.2518,
      "step": 1510
    },
    {
      "epoch": 22.028985507246375,
      "grad_norm": 0.8405202031135559,
      "learning_rate": 1.2289855072463768e-05,
      "loss": 1.3165,
      "step": 1520
    },
    {
      "epoch": 22.17391304347826,
      "grad_norm": 0.8116297721862793,
      "learning_rate": 1.1710144927536231e-05,
      "loss": 1.2588,
      "step": 1530
    },
    {
      "epoch": 22.318840579710145,
      "grad_norm": 0.6488227248191833,
      "learning_rate": 1.1130434782608696e-05,
      "loss": 1.2272,
      "step": 1540
    },
    {
      "epoch": 22.463768115942027,
      "grad_norm": 1.4836572408676147,
      "learning_rate": 1.055072463768116e-05,
      "loss": 1.21,
      "step": 1550
    },
    {
      "epoch": 22.463768115942027,
      "eval_loss": 1.2929381132125854,
      "eval_runtime": 0.2459,
      "eval_samples_per_second": 252.113,
      "eval_steps_per_second": 32.531,
      "step": 1550
    },
    {
      "epoch": 22.608695652173914,
      "grad_norm": 2.3543293476104736,
      "learning_rate": 9.971014492753623e-06,
      "loss": 1.3118,
      "step": 1560
    },
    {
      "epoch": 22.753623188405797,
      "grad_norm": 1.1780141592025757,
      "learning_rate": 9.391304347826087e-06,
      "loss": 1.2481,
      "step": 1570
    },
    {
      "epoch": 22.89855072463768,
      "grad_norm": 1.3751732110977173,
      "learning_rate": 8.81159420289855e-06,
      "loss": 1.2282,
      "step": 1580
    },
    {
      "epoch": 23.043478260869566,
      "grad_norm": 0.8365733027458191,
      "learning_rate": 8.231884057971016e-06,
      "loss": 1.2077,
      "step": 1590
    },
    {
      "epoch": 23.18840579710145,
      "grad_norm": 3.06780743598938,
      "learning_rate": 7.652173913043479e-06,
      "loss": 1.2778,
      "step": 1600
    },
    {
      "epoch": 23.18840579710145,
      "eval_loss": 1.2917101383209229,
      "eval_runtime": 0.2634,
      "eval_samples_per_second": 235.389,
      "eval_steps_per_second": 30.373,
      "step": 1600
    },
    {
      "epoch": 23.333333333333332,
      "grad_norm": 0.7924898266792297,
      "learning_rate": 7.072463768115941e-06,
      "loss": 1.2458,
      "step": 1610
    },
    {
      "epoch": 23.47826086956522,
      "grad_norm": 0.9516469836235046,
      "learning_rate": 6.492753623188406e-06,
      "loss": 1.244,
      "step": 1620
    },
    {
      "epoch": 23.6231884057971,
      "grad_norm": 3.6141250133514404,
      "learning_rate": 5.9130434782608696e-06,
      "loss": 1.2673,
      "step": 1630
    },
    {
      "epoch": 23.768115942028984,
      "grad_norm": 0.9581459164619446,
      "learning_rate": 5.333333333333334e-06,
      "loss": 1.1976,
      "step": 1640
    },
    {
      "epoch": 23.91304347826087,
      "grad_norm": 0.8805165886878967,
      "learning_rate": 4.753623188405797e-06,
      "loss": 1.2889,
      "step": 1650
    },
    {
      "epoch": 23.91304347826087,
      "eval_loss": 1.2909897565841675,
      "eval_runtime": 0.2163,
      "eval_samples_per_second": 286.646,
      "eval_steps_per_second": 36.987,
      "step": 1650
    },
    {
      "epoch": 24.057971014492754,
      "grad_norm": 1.027718424797058,
      "learning_rate": 4.173913043478261e-06,
      "loss": 1.3115,
      "step": 1660
    },
    {
      "epoch": 24.202898550724637,
      "grad_norm": 1.2655378580093384,
      "learning_rate": 3.5942028985507247e-06,
      "loss": 1.3414,
      "step": 1670
    },
    {
      "epoch": 24.347826086956523,
      "grad_norm": 4.04243278503418,
      "learning_rate": 3.0144927536231884e-06,
      "loss": 1.207,
      "step": 1680
    },
    {
      "epoch": 24.492753623188406,
      "grad_norm": 0.8235699534416199,
      "learning_rate": 2.434782608695652e-06,
      "loss": 1.1904,
      "step": 1690
    },
    {
      "epoch": 24.63768115942029,
      "grad_norm": 0.757545530796051,
      "learning_rate": 1.855072463768116e-06,
      "loss": 1.2316,
      "step": 1700
    },
    {
      "epoch": 24.63768115942029,
      "eval_loss": 1.290091633796692,
      "eval_runtime": 0.2173,
      "eval_samples_per_second": 285.341,
      "eval_steps_per_second": 36.818,
      "step": 1700
    },
    {
      "epoch": 24.782608695652176,
      "grad_norm": 0.6844388842582703,
      "learning_rate": 1.2753623188405796e-06,
      "loss": 1.2979,
      "step": 1710
    },
    {
      "epoch": 24.92753623188406,
      "grad_norm": 0.7835901975631714,
      "learning_rate": 6.956521739130435e-07,
      "loss": 1.2617,
      "step": 1720
    }
  ],
  "logging_steps": 10,
  "max_steps": 1725,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 25,
  "save_steps": 50,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 303131197440000.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
